{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful Elasticsearch Feedback Workflow for Metrics Server\n",
    "In this example we will add statistical performance metrics capabilities by levering the Seldon metrics server with persistence through the elasticsearch setup.\n",
    "\n",
    "Dependencies\n",
    "* Seldon Core installed\n",
    "* Ingress provider (Istio or Ambassador)\n",
    "* Install [Elasticsearch for the Seldon Core Logging](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/logging.html)\n",
    "* KNative eventing v0.11.0\n",
    "* KNative serving v0.11.1 (optional)\n",
    "\n",
    "Then port-forward to that ingress on localhost:8003 in a separate terminal either with:\n",
    "\n",
    "Ambassador:\n",
    "\n",
    "    kubectl port-forward $(kubectl get pods -n seldon -l app.kubernetes.io/name=ambassador -o jsonpath='{.items[0].metadata.name}') -n seldon 8003:8080\n",
    "\n",
    "Istio:\n",
    "\n",
    "    kubectl port-forward $(kubectl get pods -l istio=ingressgateway -n istio-system -o jsonpath='{.items[0].metadata.name}') -n istio-system 8003:80\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements-dev.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements-dev.txt\n",
    "elasticsearch==7.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch==7.9.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/b7/f8f03019089671486e2910282c1b6fce26ccc8a513322df72ac8994ab2de/elasticsearch-7.9.1-py2.py3-none-any.whl (219kB)\n",
      "\u001b[K     |████████████████████████████████| 225kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi in /home/alejandro/miniconda3/lib/python3.7/site-packages (from elasticsearch==7.9.1->-r requirements-dev.txt (line 1)) (2019.9.11)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from elasticsearch==7.9.1->-r requirements-dev.txt (line 1)) (1.24.2)\n",
      "Installing collected packages: elasticsearch\n",
      "  Found existing installation: elasticsearch 7.5.1\n",
      "    Uninstalling elasticsearch-7.5.1:\n",
      "      Successfully uninstalled elasticsearch-7.5.1\n",
      "Successfully installed elasticsearch-7.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements-dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/seldon created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace seldon || echo \"namespace already created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"docker-desktop\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Knative eventing routing for request logger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/seldon labeled\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl label namespace seldon-logs knative-eventing-injection=enabled --overwrite=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding payload request logger component for redirection of logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger.eventing.knative.dev/seldon-request-logger-trigger unchanged\n",
      "deployment.apps/seldon-request-logger configured\n",
      "service/seldon-request-logger unchanged\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl apply -f - << END\n",
    "apiVersion: eventing.knative.dev/v1alpha1\n",
    "kind: Trigger\n",
    "metadata:\n",
    " name: seldon-request-logger-trigger\n",
    " namespace: seldon-logs\n",
    "spec:\n",
    " subscriber:\n",
    "   ref:\n",
    "     apiVersion: v1\n",
    "     kind: Service\n",
    "     name: seldon-request-logger\n",
    "END\n",
    "\n",
    "kubectl apply -f - << END\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    " name: seldon-request-logger\n",
    " namespace: seldon-logs\n",
    " labels:\n",
    "   app: seldon-request-logger\n",
    "spec:\n",
    " replicas: 1\n",
    " selector:\n",
    "   matchLabels:\n",
    "     app: seldon-request-logger\n",
    " template:\n",
    "   metadata:\n",
    "     labels:\n",
    "       app: seldon-request-logger\n",
    "   spec:\n",
    "     containers:\n",
    "       - name: user-container\n",
    "         image: docker.io/seldonio/seldon-request-logger:1.4.0-dev\n",
    "         imagePullPolicy: IfNotPresent\n",
    "         env:\n",
    "           - name: ELASTICSEARCH_HOST\n",
    "             value: \"elasticsearch-master.seldon-logs.svc.cluster.local\"\n",
    "           - name: ELASTICSEARCH_PORT\n",
    "             value: \"9200\"\n",
    "END\n",
    "\n",
    "kubectl apply -f - << END\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    " name: seldon-request-logger\n",
    " namespace: seldon-logs\n",
    "spec:\n",
    " selector:\n",
    "   app: seldon-request-logger\n",
    " ports:\n",
    "   - protocol: TCP\n",
    "     port: 80\n",
    "     targetPort: 8080\n",
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple model\n",
    "We create a multiclass classification model - iris classifier.\n",
    "\n",
    "The iris classifier takes an input array, and returns the prediction of the 4 classes.\n",
    "\n",
    "The prediction can be done as numeric or as a probability array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/multiclass-model configured\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl apply -f - << END\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: multiclass-model\n",
    "spec:\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: gs://seldon-models/sklearn/iris\n",
    "      name: classifier\n",
    "      logger:\n",
    "        url: http://default-broker.seldon-logs.svc.cluster.local:80/\n",
    "        mode: all\n",
    "    name: default\n",
    "    replicas: 1\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment \"multiclass-model-default-0-classifier\" successfully rolled out\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=multiclass-model -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Prediction Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://localhost:80/seldon/seldon/multiclass-model/api/v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'names': ['t:0', 't:1', 't:2'], 'ndarray': [[0.0006985194531162841, 0.003668039039435755, 0.9956334415074478]]}, 'meta': {}}\n"
     ]
    }
   ],
   "source": [
    "pred_req_1 = {\"data\":{\"ndarray\":[[1,2,3,4]]}}\n",
    "pred_resp_1 = requests.post(f\"{url}/predictions\", json=pred_req_1)\n",
    "print(pred_resp_1.json())\n",
    "assert(len(pred_resp_1.json()[\"data\"][\"ndarray\"][0])==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data in Elasticsearch\n",
    "We'll be able to check the elasticsearch through the service or the pods in our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(['http://localhost:9200'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the indices that have been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inference-log-seldon-seldon-new-multiclass-model-default': {'aliases': {}},\n",
       " 'inference-log-seldon-seldon-multiclass-model-shadow': {'aliases': {}},\n",
       " 'inference-log-seldon-seldon-multiclass-model-default': {'aliases': {}},\n",
       " 'inference-log-seldon-seldon-multiclass-model-canary': {'aliases': {}}}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.get_alias(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1f84e43-41e8-4c92-a704-e2493a7f1c6e\n"
     ]
    }
   ],
   "source": [
    "puid_seldon_1 = pred_resp_1.headers.get(\"seldon-puid\")\n",
    "\n",
    "print(puid_seldon_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data that is stored in the elasticsearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Request:\n",
      "{'ce-source': 'http::8000', 'instance': [1.0, 2.0, 3.0, 4.0], 'payload': {'data': {'ndarray': [[1, 2, 3, 4]]}}, 'dataType': 'tabular', 'elements': {}, 'ce-time': '2020-11-06T08:53:24.964905828Z'}\n",
      "\n",
      "Logged Response:\n",
      "{'payload': {'data': {'names': ['t:0', 't:1', 't:2'], 'ndarray': [[0.0006985194531162841, 0.003668039039435755, 0.9956334415074478]]}, 'meta': {}}, 'dataType': 'tabular', 'elements': {'t:0': [0.0006985194531162841], 't:1': [0.003668039039435755], 't:2': [0.9956334415074478]}, 'instance': [0.0006985194531162841, 0.003668039039435755, 0.9956334415074478], 'names': ['t:0', 't:1', 't:2'], 'ce-time': '2020-11-06T08:53:24.978390228Z', 'ce-source': 'http::8000'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index=\"inference-log-seldon-seldon-multiclass-model-default\", body={\"query\": {\"match\": { \"_id\": puid_seldon_1 }}})\n",
    "print(\"Logged Request:\")\n",
    "print(res[\"hits\"][\"hits\"][0][\"_source\"][\"request\"])\n",
    "print(\"\\nLogged Response:\")\n",
    "print(res[\"hits\"][\"hits\"][0][\"_source\"][\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send feedback\n",
    "\n",
    "We can now send the correction, or the truth value of the prediction.\n",
    "\n",
    "For this we'll need to send the UUID of the feedback request to ensure it's added to the correct index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also be able to add extra metadata, such as the user providing the feedback, date, time, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_tags_1 = {\n",
    "    \"user\": \"Seldon Admin\",\n",
    "    \"date\": \"11/07/2020\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can put together the feedback request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_req_1 = {\n",
    "    \"reward\": 0,\n",
    "    \"truth\": {\n",
    "        'data': {\n",
    "            'names': ['t:0', 't:1', 't:2'], \n",
    "            'ndarray': [[0, 0, 1]]\n",
    "        },\n",
    "        \"meta\": {\n",
    "            \"tags\": feedback_tags_1\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And send the feedback request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "feedback_resp_1 = requests.post(f\"{url}/feedback\", json=feedback_req_1, headers={\"seldon-puid\": puid_seldon_1})\n",
    "print(feedback_resp_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that feedback has been received and stored in the Elasticsearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reward': 0, 'ce-source': 'http::8000', 'truth': {'data': {'names': ['t:0', 't:1', 't:2'], 'ndarray': [[0, 0, 1]]}, 'meta': {'tags': {'date': '11/07/2020', 'user': 'Seldon Admin'}}}, 'ce-time': '2020-11-06T08:53:36.164873988Z'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index=\"inference-log-seldon-seldon-multiclass-model-default\", body={\"query\": {\"match\": { \"_id\": puid_seldon_1 }}})\n",
    "\n",
    "print(res[\"hits\"][\"hits\"][-1][\"_source\"][\"feedback\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Metrics Server\n",
    "\n",
    "Now we'll be able to see how the metrics server makes use of this infrastructure patterns to provide real time performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config/multiclass-deployment.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/multiclass-deployment.yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: seldon-multiclass-model-metrics\n",
    "  labels:\n",
    "    app: seldon-multiclass-model-metrics\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: seldon-multiclass-model-metrics\n",
    "  template:\n",
    "    metadata:\n",
    "      annotations:\n",
    "        prometheus.io/path: /v1/metrics\n",
    "        prometheus.io/scrape: \"true\"\n",
    "      labels:\n",
    "        app: seldon-multiclass-model-metrics\n",
    "    spec:\n",
    "      securityContext:\n",
    "          runAsUser: 8888\n",
    "      containers:\n",
    "      - name: user-container\n",
    "        image: seldonio/alibi-detect-server:1.4.0-dev\n",
    "        imagePullPolicy: IfNotPresent\n",
    "        args:\n",
    "        - --model_name\n",
    "        - multiclassserver\n",
    "        - --http_port\n",
    "        - '8080'\n",
    "        - --protocol\n",
    "        - seldonfeedback.http\n",
    "        - --storage_uri\n",
    "        - \"adserver.cm_models.multiclass_one_hot.MulticlassOneHot\"\n",
    "        - --reply_url\n",
    "        - http://message-dumper.default        \n",
    "        - --event_type\n",
    "        - io.seldon.serving.feedback.metrics\n",
    "        - --event_source\n",
    "        - io.seldon.serving.feedback\n",
    "        - --elasticsearch_uri\n",
    "        - http://elasticsearch-master.seldon-logs:9200\n",
    "        - MetricsServer\n",
    "        env:\n",
    "        - name: \"SELDON_DEPLOYMENT_ID\"\n",
    "          value: \"multiclass-model\"\n",
    "        - name: \"PREDICTIVE_UNIT_ID\"\n",
    "          value: \"classifier\"\n",
    "        - name: \"PREDICTIVE_UNIT_IMAGE\"\n",
    "          value: \"alibi-detect-server:1.3.0-dev\"\n",
    "        - name: \"PREDICTOR_ID\"\n",
    "          value: \"default\"\n",
    "        ports:\n",
    "        - containerPort: 8080\n",
    "          name: metrics\n",
    "          protocol: TCP\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: seldon-multiclass-model-metrics\n",
    "  labels:\n",
    "    app: seldon-multiclass-model-metrics\n",
    "spec:\n",
    "  selector:\n",
    "    app: seldon-multiclass-model-metrics\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 80\n",
    "      targetPort: 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/seldon-multiclass-model-metrics configured\n",
      "service/seldon-multiclass-model-metrics unchanged\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -n seldon -f config/multiclass-deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment \"seldon-multiclass-model-metrics\" successfully rolled out\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/seldon-multiclass-model-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger for metrics server\n",
    "\n",
    "The trigger will be created in the seldon-logs namespace as that is where the initial trigger will be sent to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger.eventing.knative.dev/multiclass-model-metrics-trigger created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl apply -f - << END\n",
    "apiVersion: eventing.knative.dev/v1alpha1\n",
    "kind: Trigger\n",
    "metadata:\n",
    "  name: multiclass-model-metrics-trigger\n",
    "  namespace: seldon-logs\n",
    "spec:\n",
    "  filter:\n",
    "    sourceAndType:\n",
    "      type: io.seldon.serving.feedback\n",
    "  subscriber:\n",
    "    uri: http://seldon-multiclass-model-metrics.seldon:80\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Alternative) create kservice\n",
    "\n",
    "If you want to create a kservice, and you've installed knative eventing and knative serving, you can use the instructions below.\n",
    "\n",
    "The value of the file `config/multiclass-service.yaml` would be:\n",
    "```\n",
    "apiVersion: serving.knative.dev/v1alpha1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: seldon-multiclass-model-metrics\n",
    "spec:\n",
    "  template:\n",
    "    metadata:\n",
    "      annotations:\n",
    "        prometheus.io/path: /v1/metrics\n",
    "        prometheus.io/scrape: \"true\"\n",
    "        autoscaling.knative.dev/minScale: \"1\"\n",
    "    spec:\n",
    "      containers:\n",
    "      - image: \"seldonio/alibi-detect-server:1.4.0-dev\"\n",
    "        args:\n",
    "        - --model_name\n",
    "        - multiclassserver\n",
    "        - --http_port\n",
    "        - '8080'\n",
    "        - --protocol\n",
    "        - seldonfeedback.http\n",
    "        - --storage_uri\n",
    "        - \"adserver.cm_models.multiclass_one_hot.MulticlassOneHot\"\n",
    "        - --reply_url\n",
    "        - http://message-dumper.default        \n",
    "        - --event_type\n",
    "        - io.seldon.serving.feedback.metrics\n",
    "        - --event_source\n",
    "        - io.seldon.serving.feedback\n",
    "        - MetricsServer\n",
    "        env:\n",
    "        - name: \"SELDON_DEPLOYMENT_ID\"\n",
    "          value: \"multiclass-model\"\n",
    "        - name: \"PREDICTIVE_UNIT_ID\"\n",
    "          value: \"classifier\"\n",
    "        - name: \"PREDICTIVE_UNIT_IMAGE\"\n",
    "          value: \"alibi-detect-server:1.3.0-dev\"\n",
    "        - name: \"PREDICTOR_ID\"\n",
    "          value: \"default\"\n",
    "        ports:\n",
    "        - containerPort: 8080\n",
    "          name: metrics\n",
    "          protocol: TCP\n",
    "        securityContext:\n",
    "            runAsUser: 8888\n",
    "```\n",
    "\n",
    "You can run the kservice with the command below:\n",
    "```\n",
    "kubectl apply -f config/multiclass-service.yaml\n",
    "```\n",
    "And then check with:\n",
    "\n",
    "```\n",
    "kubectl get kservice\n",
    "```\n",
    "\n",
    "You'll then have to create the trigger, first by creating the broker:\n",
    "\n",
    "```\n",
    "kubectl label namespace default knative-eventing-injection=enabled --overwrite=true\n",
    "```\n",
    "\n",
    "And then the trigger contents:\n",
    "\n",
    "```\n",
    "apiVersion: eventing.knative.dev/v1alpha1\n",
    "kind: Trigger\n",
    "metadata:\n",
    "  name: multiclass-model-metrics-trigger\n",
    "  namespace: default\n",
    "spec:\n",
    "  filter:\n",
    "    sourceAndType:\n",
    "      type: io.seldon.serving.feedback\n",
    "  subscriber:\n",
    "    ref:\n",
    "      apiVersion: v1\n",
    "      kind: Service\n",
    "      name: seldon-multiclass-model-metrics\n",
    "```\n",
    "\n",
    "And you can run it with:\n",
    "```\n",
    "kubectl apply -f config/trigger.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm empty metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> GET /v1/metrics HTTP/1.1\r",
      "\r",
      "\r\n",
      "> User-Agent: curl/7.35.0\r",
      "\r",
      "\r\n",
      "> Host: seldon-multiclass-model-metrics.seldon.svc.cluster.local\r",
      "\r",
      "\r\n",
      "> Accept: */*\r",
      "\r",
      "\r\n",
      "> \r",
      "\r",
      "\r\n",
      "< HTTP/1.1 200 OK\r",
      "\r",
      "\r\n",
      "< Server: TornadoServer/6.0.4\r",
      "\r",
      "\r\n",
      "< Content-Type: text/plain; version=0.0.4; charset=utf-8\r",
      "\r",
      "\r\n",
      "< Date: Tue, 03 Nov 2020 02:16:56 GMT\r",
      "\r",
      "\r\n",
      "< Etag: \"6c89cfb2f6b1ccb59ee9882ebcece5dbd504a148\"\r",
      "\r",
      "\r\n",
      "< Content-Length: 520\r",
      "\r",
      "\r\n",
      "< \r",
      "\r",
      "\r\n",
      "# HELP seldon_metric_true_positive_total \r",
      "\r\n",
      "# TYPE seldon_metric_true_positive_total counter\r",
      "\r\n",
      "seldon_metric_true_positive_total{class=\"CLASS_2\",deployment_name=\"multiclass-model\",image_name=\"alibi-detect-server\",image_version=\"1.3.0-dev\",method=\"io.seldon.serving.feedback.metrics\",model_image=\"alibi-detect-server\",model_name=\"classifier\",model_version=\"1.3.0-dev\",predictor_name=\"default\",predictor_version=\"NOT_IMPLEMENTED\",seldon_deployment_name=\"multiclass-model\",worker_id=\"9b8f9146-1d7a-11eb-a09a-725716f0e186\"} 1.0\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl run --quiet=true -it --rm curl --image=radial/busyboxplus:curl --restart=Never -- \\\n",
    "    curl -v -X GET \"http://seldon-multiclass-model-metrics.seldon.svc.cluster.local:80/v1/metrics\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "feedback_resp_1 = requests.post(f\"{url}/feedback\", json=feedback_req_1, headers={\"seldon-puid\": puid_seldon_1})\n",
    "print(feedback_resp_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm metrics available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Couldn't resolve host 'seldon-multiclass-model-metrics.seldon'\n",
      "curl: (6) Couldn't resolve host 'seldon-multiclass-model-metrics.seldon'\n",
      "pod seldon/curl terminated (Error)\n"
     ]
    }
   ],
   "source": [
    "!kubectl run --quiet=true -it --rm curl --image=radial/busyboxplus:curl --restart=Never -- \\\n",
    "    curl -v -X GET \"http://seldon-multiclass-model-metrics.seldon:80/v1/metrics\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Grafana Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be able to access the grafana dashboard for the model. You can access it by port-forwarding the grafana dashboard with:\n",
    "```\n",
    "kubectl port-forward -n seldon-system svc/seldon-core-analytics-grafana 7000:80\n",
    "```\n",
    "\n",
    "And you can load the following dashboard via the import tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"annotations\": {\"list\": [{\"builtIn\": 1,\"datasource\": \"-- Grafana --\",\"enable\": true,\"hide\": true,\"iconColor\": \"rgba(0, 211, 255, 1)\",\"name\": \"Annotations & Alerts\",\"type\": \"dashboard\"}]},\"editable\": true,\"gnetId\": null,\"graphTooltip\": 0,\"id\": 4,\"links\": [],\"panels\": [{\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {},\"mappings\": [],\"thresholds\": {\"mode\": \"absolute\",\"steps\": [{\"color\": \"green\",\"value\": null},{\"color\": \"red\",\"value\": 80}]}},\"overrides\": []},\"gridPos\": {\"h\": 5,\"w\": 8,\"x\": 0,\"y\": 0},\"id\": 5,\"options\": {\"colorMode\": \"background\",\"graphMode\": \"area\",\"justifyMode\": \"auto\",\"orientation\": \"auto\",\"reduceOptions\": {\"calcs\": [\"mean\"],\"fields\": \"\",\"values\": false}},\"pluginVersion\": \"7.0.3\",\"targets\": [{\"expr\": \"((sum(seldon_metric_true_positive_total) by (seldon_deployment_name) + sum(seldon_metric_true_negative_total) by (seldon_deployment_name))  /  (sum(seldon_metric_true_positive_total) by (seldon_deployment_name) + sum(seldon_metric_false_positive_total) by (seldon_deployment_name) + sum(seldon_metric_false_negative_total) by (seldon_deployment_name))) \",\"format\": \"time_series\",\"instant\": false,\"interval\": \"\",\"legendFormat\": \"{{class}} - {{seldon_app}}\",\"refId\": \"A\"}],\"timeFrom\": null,\"timeShift\": null,\"title\": \"ACCURACY\",\"transparent\": true,\"type\": \"stat\"},{\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {},\"mappings\": [],\"thresholds\": {\"mode\": \"absolute\",\"steps\": [{\"color\": \"green\",\"value\": null},{\"color\": \"red\",\"value\": 80}]}},\"overrides\": []},\"gridPos\": {\"h\": 5,\"w\": 8,\"x\": 8,\"y\": 0},\"id\": 6,\"options\": {\"colorMode\": \"value\",\"graphMode\": \"area\",\"justifyMode\": \"auto\",\"orientation\": \"auto\",\"reduceOptions\": {\"calcs\": [\"mean\"],\"fields\": \"\",\"values\": false}},\"pluginVersion\": \"7.0.3\",\"targets\": [{\"expr\": \"(sum(seldon_metric_true_positive_total) by (seldon_deployment_name)  /  (sum(seldon_metric_true_positive_total) by (seldon_deployment_name) + sum(seldon_metric_false_positive_total) by (seldon_deployment_name))) \",\"instant\": false,\"interval\": \"\",\"legendFormat\": \"{{class}} - {{seldon_deployment_name}}\",\"refId\": \"A\"}],\"timeFrom\": null,\"timeShift\": null,\"title\": \"PRECISION\",\"transparent\": true,\"type\": \"stat\"},{\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {},\"mappings\": [],\"thresholds\": {\"mode\": \"absolute\",\"steps\": [{\"color\": \"green\",\"value\": null},{\"color\": \"red\",\"value\": 80}]}},\"overrides\": []},\"gridPos\": {\"h\": 5,\"w\": 8,\"x\": 16,\"y\": 0},\"id\": 7,\"options\": {\"colorMode\": \"value\",\"graphMode\": \"area\",\"justifyMode\": \"auto\",\"orientation\": \"auto\",\"reduceOptions\": {\"calcs\": [\"mean\"],\"fields\": \"\",\"values\": false}},\"pluginVersion\": \"7.0.3\",\"targets\": [{\"expr\": \"(sum(seldon_metric_true_positive_total) by (seldon_deployment_name)  /  (sum(seldon_metric_true_positive_total) by (seldon_deployment_name) + sum(seldon_metric_false_negative_total) by (seldon_deployment_name))) \",\"instant\": false,\"interval\": \"\",\"legendFormat\": \"{{class}} - {{seldon_app}}\",\"refId\": \"A\"}],\"timeFrom\": null,\"timeShift\": null,\"title\": \"Recall\",\"transparent\": true,\"type\": \"stat\"},{\"aliasColors\": {},\"bars\": false,\"dashLength\": 10,\"dashes\": false,\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {}},\"overrides\": []},\"fill\": 1,\"fillGradient\": 0,\"gridPos\": {\"h\": 6,\"w\": 24,\"x\": 0,\"y\": 5},\"hiddenSeries\": false,\"id\": 3,\"legend\": {\"avg\": false,\"current\": false,\"max\": false,\"min\": false,\"show\": true,\"total\": false,\"values\": false},\"lines\": true,\"linewidth\": 1,\"nullPointMode\": \"null\",\"options\": {\"dataLinks\": []},\"percentage\": false,\"pointradius\": 2,\"points\": true,\"renderer\": \"flot\",\"seriesOverrides\": [],\"spaceLength\": 10,\"stack\": false,\"steppedLine\": false,\"targets\": [{\"expr\": \"((sum(seldon_metric_true_positive_total) by (class, seldon_deployment_name) + sum(seldon_metric_true_negative_total) by (class, seldon_deployment_name))  /  (sum(seldon_metric_true_positive_total) by (class, seldon_deployment_name) + sum(seldon_metric_false_positive_total) by (class, seldon_deployment_name) + sum(seldon_metric_false_negative_total) by (class, seldon_deployment_name))) \",\"interval\": \"\",\"legendFormat\": \"{{class}} - {{seldon_deployment_name}}\",\"refId\": \"A\"}],\"thresholds\": [],\"timeFrom\": null,\"timeRegions\": [],\"timeShift\": null,\"title\": \"Real Time Model ACCURACY by Class\",\"tooltip\": {\"shared\": true,\"sort\": 0,\"value_type\": \"individual\"},\"transparent\": true,\"type\": \"graph\",\"xaxis\": {\"buckets\": null,\"mode\": \"time\",\"name\": null,\"show\": true,\"values\": []},\"yaxes\": [{\"decimals\": null,\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": \"1\",\"min\": \"0\",\"show\": true},{\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": null,\"min\": null,\"show\": true}],\"yaxis\": {\"align\": false,\"alignLevel\": null}},{\"aliasColors\": {},\"bars\": false,\"dashLength\": 10,\"dashes\": false,\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {}},\"overrides\": []},\"fill\": 1,\"fillGradient\": 0,\"gridPos\": {\"h\": 7,\"w\": 12,\"x\": 0,\"y\": 11},\"hiddenSeries\": false,\"id\": 2,\"legend\": {\"avg\": false,\"current\": false,\"max\": false,\"min\": false,\"show\": true,\"total\": false,\"values\": false},\"lines\": true,\"linewidth\": 1,\"nullPointMode\": \"null\",\"options\": {\"dataLinks\": []},\"percentage\": false,\"pointradius\": 2,\"points\": true,\"renderer\": \"flot\",\"seriesOverrides\": [],\"spaceLength\": 10,\"stack\": false,\"steppedLine\": false,\"targets\": [{\"expr\": \"((sum(seldon_metric_true_positive_total) by (class, seldon_deployment_name))  /  (sum(seldon_metric_true_positive_total) by (class, seldon_deployment_name) + sum(seldon_metric_false_positive_total) by (class, seldon_deployment_name))) \",\"interval\": \"\",\"legendFormat\": \"{{class}} - {{seldon_deployment_name}}\",\"refId\": \"A\"}],\"thresholds\": [],\"timeFrom\": null,\"timeRegions\": [],\"timeShift\": null,\"title\": \"Real Time Model PRECISION by Class\",\"tooltip\": {\"shared\": true,\"sort\": 0,\"value_type\": \"individual\"},\"type\": \"graph\",\"xaxis\": {\"buckets\": null,\"mode\": \"time\",\"name\": null,\"show\": true,\"values\": []},\"yaxes\": [{\"decimals\": null,\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": \"1\",\"min\": \"0\",\"show\": true},{\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": null,\"min\": null,\"show\": true}],\"yaxis\": {\"align\": false,\"alignLevel\": null}},{\"aliasColors\": {},\"bars\": false,\"dashLength\": 10,\"dashes\": false,\"datasource\": \"prometheus\",\"description\": \"\",\"fieldConfig\": {\"defaults\": {\"custom\": {}},\"overrides\": []},\"fill\": 1,\"fillGradient\": 0,\"gridPos\": {\"h\": 7,\"w\": 12,\"x\": 12,\"y\": 11},\"hiddenSeries\": false,\"id\": 4,\"legend\": {\"avg\": false,\"current\": false,\"max\": false,\"min\": false,\"show\": true,\"total\": false,\"values\": false},\"lines\": true,\"linewidth\": 1,\"nullPointMode\": \"null\",\"options\": {\"dataLinks\": []},\"percentage\": false,\"pointradius\": 2,\"points\": true,\"renderer\": \"flot\",\"seriesOverrides\": [],\"spaceLength\": 10,\"stack\": false,\"steppedLine\": false,\"targets\": [{\"expr\": \"((sum(seldon_metric_true_negative_total) by (class, seldon_deployment_name))  /  (sum(seldon_metric_true_positive_total) by (class, seldon_deployment_name) + sum(seldon_metric_false_negative_total) by (class, seldon_deployment_name))) \",\"interval\": \"\",\"legendFormat\": \"{{class}} - {{seldon_deployment_name}}\",\"refId\": \"A\"}],\"thresholds\": [],\"timeFrom\": null,\"timeRegions\": [],\"timeShift\": null,\"title\": \"Real Time Model RECALL by Class\",\"tooltip\": {\"shared\": true,\"sort\": 0,\"value_type\": \"individual\"},\"type\": \"graph\",\"xaxis\": {\"buckets\": null,\"mode\": \"time\",\"name\": null,\"show\": true,\"values\": []},\"yaxes\": [{\"decimals\": null,\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": \"1\",\"min\": \"0\",\"show\": true},{\"format\": \"short\",\"label\": null,\"logBase\": 1,\"max\": null,\"min\": null,\"show\": true}],\"yaxis\": {\"align\": false,\"alignLevel\": null}}],\"refresh\": false,\"schemaVersion\": 25,\"style\": \"dark\",\"tags\": [],\"templating\": {\"list\": []},\"time\": {\"from\": \"2020-11-03T12:06:17.311Z\",\"to\": \"2020-11-03T13:06:17.315Z\"},\"timepicker\": {\"refresh_intervals\": [\"10s\",\"30s\",\"1m\",\"5m\",\"15m\",\"30m\",\"1h\",\"2h\",\"1d\"]},\"timezone\": \"\",\"title\": \"Real Time Statistical Performance\",\"uid\": \"St9vqHnGk\",\"version\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download prediction and feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "X_test, y_test = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# convert y to one hot\n",
    "y_test = np.eye(y_test.max() + 1)[y_test]\n",
    "print(y_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Prediction Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "puids = []\n",
    "\n",
    "for x in X_test:\n",
    "    pred_req = {\"data\":{\"ndarray\":[x.tolist()]}}\n",
    "    pred_resp = requests.post(f\"{url}/predictions\", json=pred_req)\n",
    "    \n",
    "    puid_seldon = pred_resp.headers.get(\"seldon-puid\")\n",
    "    puids.append(puid_seldon)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['e10985c5-a032-4414-af1b-17473ca16e42', '884b98c9-c79c-401f-a5a3-9567f508e0f8']"
      ],
      "text/plain": [
       "['e10985c5-a032-4414-af1b-17473ca16e42',\n",
       " '884b98c9-c79c-401f-a5a3-9567f508e0f8']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puids[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for puid, y in zip(puids, y_test):\n",
    "    data = {\n",
    "        \"truth\": {\n",
    "            'data': {\n",
    "                'names': ['t:0', 't:1', 't:2'], \n",
    "                'ndarray': [y.tolist()]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    requests.post(f\"{url}/feedback\", json=data, headers={\"seldon-puid\": puid})\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send randomized metrics to visualise degrade performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rand = np.array(y_test)\n",
    "np.random.shuffle(y_rand)\n",
    "for puid, y in zip(puids, y_rand):\n",
    "    data = {\n",
    "        \"truth\": {\n",
    "            'data': {\n",
    "                'names': ['t:0', 't:1', 't:2'], \n",
    "                'ndarray': [y.tolist()]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    requests.post(f\"{url}/feedback\", json=data, headers={\"seldon-puid\": puid})\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIsualise metrics\n",
    "\n",
    "Now you should be able to see real time performance in the dashboard for \"Accuracy\", \"Precision\" and \"Recall\".\n",
    "\n",
    "Furthermore you should also be able to get further insights from the data that is stored in Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from alibi.explainers import AnchorTabular\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_iris()\n",
    "feature_names = dataset.feature_names\n",
    "class_names = list(dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 145\n",
    "X_train,Y_train = dataset.data[:idx,:], dataset.target[:idx]\n",
    "X_test, Y_test = dataset.data[idx+1:,:], dataset.target[idx+1:]\n",
    "\n",
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "\n",
    "np.random.seed(0)\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [6.3 2.5 5.  1.9]\n",
      "Prediction:  virginica\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print('Input: ', X_test[idx])\n",
    "print('Prediction: ', class_names[explainer.predictor(X_test[idx].reshape(1, -1))[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "with open(\"model.joblib\", \"wb\") as file:\n",
    "    joblib.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/multiclass-model configured\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl apply -f - << END\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: multiclass-model\n",
    "spec:\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: gs://seldon-models/sklearn/iris\n",
    "      name: classifier\n",
    "      logger:\n",
    "        url: http://default-broker.seldon-logs.svc.cluster.local:80/\n",
    "        mode: all\n",
    "    name: default\n",
    "    replicas: 1\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass-model-default-0-classifier-776746677-m5xr6   2/2     Running   0          12h\r\n",
      "seldon-multiclass-model-metrics-57b6749597-d9dk2        1/1     Running   0          42h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods | grep multiclass-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send requests to visualise system performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-531be4d9ed61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpred_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ndarray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpred_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{url}/predictions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \"\"\"\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    for x in X:\n",
    "        pred_req = {\"data\":{\"ndarray\":[x.tolist()]}}\n",
    "\n",
    "        pred_resp = requests.post(f\"{url}/predictions\", json=pred_req)\n",
    "\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To send feedback first send requests and capture id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "puids = []\n",
    "\n",
    "for x in X:\n",
    "    pred_req = {\"data\":{\"ndarray\":[x.tolist()]}}\n",
    "    pred_resp = requests.post(f\"{url}/predictions\", json=pred_req)\n",
    "    \n",
    "    puid_seldon = pred_resp.headers.get(\"seldon-puid\")\n",
    "    puids.append(puid_seldon)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send feedback to visualise statistical performance (actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = np.eye(Y.max() + 1)[Y] # Covert to one hot\n",
    "for puid, y in zip(puids, y_one_hot):\n",
    "    data = {\n",
    "        \"truth\": {\n",
    "            'data': {\n",
    "                'names': ['t:0', 't:1', 't:2'], \n",
    "                'ndarray': [y.tolist()]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    requests.post(f\"{url}/feedback\", json=data, headers={\"seldon-puid\": puid})\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send feedback to visualise statistical performance (Skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-e8d0476a76aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         }\n\u001b[1;32m     14\u001b[0m         \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{url}/feedback\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"seldon-puid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpuid\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_one_hot = np.eye(Y.max() + 1)[Y] # Covert to one hot\n",
    "y_rand = np.array(y_one_hot)\n",
    "np.random.shuffle(y_rand)\n",
    "while True:\n",
    "    for puid, y in zip(puids, y_rand):\n",
    "        data = {\n",
    "            \"truth\": {\n",
    "                'data': {\n",
    "                    'names': ['t:0', 't:1', 't:2'], \n",
    "                    'ndarray': [y.tolist()]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        requests.post(f\"{url}/feedback\", json=data, headers={\"seldon-puid\": puid})\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainer\n",
    "Now we can train and deploy an explainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTabular(meta={\n",
       "    'name': 'AnchorTabular',\n",
       "    'type': ['blackbox'],\n",
       "    'explanations': ['local'],\n",
       "    'params': {'seed': None, 'disc_perc': (25, 50, 75)}\n",
       "})"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fn = lambda x: clf.predict_proba(x)\n",
    "\n",
    "explainer = AnchorTabular(predict_fn, feature_names)\n",
    "\n",
    "explainer.fit(X_train, disc_perc=(25, 50, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose datapoint and prediction to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [6.3 2.5 5.  1.9]\n",
      "Prediction:  virginica\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print('Input: ', X_test[idx])\n",
    "print('Prediction: ', class_names[explainer.predictor(X_test[idx].reshape(1, -1))[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run explanation on datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: petal width (cm) > 1.80 AND sepal width (cm) <= 2.80\n",
      "Precision: 0.96\n",
      "Coverage: 0.32\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(X_test[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"explainer.dill\", \"wb\") as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explainer.dill\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/iris-explainer configured\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "kubectl apply -f - << END\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: iris-explainer\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/rest-timeout: \"100000\"\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: gs://seldon-models/sklearn/iris\n",
    "      name: classifier\n",
    "    explainer:\n",
    "      type: AnchorTabular\n",
    "      modelUri: gs://seldon-models/sklearn/iris-0.23.2/anchor\n",
    "    name: default\n",
    "    replicas: 1\n",
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose prediction to explain (the same one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [6.3 2.5 5.  1.9]\n"
     ]
    }
   ],
   "source": [
    "print('Input: ', X_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send explanation request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_url = \"http://localhost:80/seldon/seldon/iris-explainer-explainer/default/api/v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.3, 2.5, 5.0, 1.9]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[idx].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "pred_req_1 = {\"data\":{\"ndarray\":  [X_test[idx].tolist()] }}\n",
    "explanation = requests.post(f\"{explain_url}/explain\", json=pred_req_1)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: petal width (cm) > 1.80 AND sepal width (cm) <= 2.80\n",
      "Precision: 0.98\n",
      "Coverage: 0.32\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(X_test[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"meta\": {\"name\": \"AnchorTabular\", \"type\": [\"blackbox\"], \"explanations\": [\"local\"], \"params\": {\"seed\": null, \"disc_perc\": [25, 50, 75], \"kwargs\": {}, \"verbose_every\": 1, \"verbose\": false, \"cache_margin\": 1000, \"binary_cache_size\": 10000, \"n_covered_ex\": 10, \"min_samples_start\": 100, \"max_anchor_size\": null, \"stop_on_first\": false, \"beam_size\": 1, \"coverage_samples\": 10000, \"batch_size\": 100, \"tau\": 0.15, \"delta\": 0.1, \"threshold\": 0.95}}, \"data\": {\"anchor\": [\"petal width (cm) > 1.80\", \"petal length (cm) > 4.20\"], \"precision\": 0.9873873873873874, \"coverage\": 0.496551724137931, \"raw\": {\"feature\": [3, 2], \"mean\": [0.6406388642413487, 0.9873873873873874], \"precision\": [0.6406388642413487, 0.9873873873873874], \"coverage\": [0.20689655172413793, 0.496551724137931], \"examples\": [{\"covered_true\": [[5.1, 2.5, 3.0, 2.5], [6.0, 2.9, 4.5, 1.9], [6.0, 2.2, 4.0, 2.1], [5.7, 3.0, 4.2, 2.2], [5.9, 3.0, 4.2, 2.1], [5.4, 3.0, 4.5, 2.5], [7.6, 3.0, 6.6, 1.9], [6.8, 2.8, 4.8, 2.0], [6.0, 3.4, 4.5, 2.3], [7.2, 3.2, 6.0, 2.2]], \"covered_false\": [[5.3, 3.7, 1.5, 2.0], [4.3, 3.0, 1.1, 2.1], [5.0, 3.2, 1.2, 2.4], [5.7, 3.8, 1.7, 1.9], [4.5, 2.3, 1.3, 2.3], [4.9, 3.0, 1.4, 2.5], [4.8, 3.0, 1.4, 2.3], [5.0, 3.3, 1.4, 2.3], [5.4, 3.7, 1.5, 1.9], [5.4, 3.7, 1.5, 2.0]], \"uncovered_true\": [], \"uncovered_false\": []}, {\"covered_true\": [[6.4, 2.7, 6.0, 2.5], [6.3, 2.9, 5.1, 1.9], [6.3, 2.7, 5.9, 2.1], [5.8, 2.7, 5.8, 2.2], [5.5, 2.5, 6.6, 2.1], [6.4, 2.9, 6.1, 2.5], [5.8, 2.7, 5.1, 2.0], [6.4, 3.1, 5.3, 1.9], [6.4, 2.8, 5.5, 2.1], [4.4, 3.0, 5.0, 2.0]], \"covered_false\": [[6.7, 3.3, 4.5, 1.9], [7.9, 3.8, 4.4, 2.1], [6.9, 3.1, 4.7, 1.9], [6.7, 3.0, 4.4, 2.0], [7.7, 2.8, 4.5, 2.0]], \"uncovered_true\": [], \"uncovered_false\": []}], \"all_precision\": 0, \"num_preds\": 1000000, \"success\": true, \"names\": [\"petal width (cm) > 1.80\", \"petal length (cm) > 4.20\"], \"prediction\": [2], \"instance\": [6.3, 2.5, 5.0, 1.9], \"instances\": [[6.3, 2.5, 5.0, 1.9]]}}}"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\": {\"names\": [\"text\"], \"ndarray\": [[6.3, 2.5, 5.0, 1.9]]}}' \\\n",
    "    http://localhost:80/seldon/seldon/iris-explainer-explainer/default/api/v1.0/explain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
